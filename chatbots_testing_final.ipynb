{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "9d38c991-0011-4bd5-99c1-ba0154b355aa",
      "metadata": {
        "id": "9d38c991-0011-4bd5-99c1-ba0154b355aa"
      },
      "source": [
        "# ٍSteps of creating chatbot:\n",
        "# 1-Stemming(إرجاع كل كلمه لاصلها)\n",
        "# 2-Remove Stopword (إزالة الكللمات التى ليس ليها قيمه كبيره لا تغير معنى الجمله)\n",
        "# 3-Word Embedding(إستخراج المعانى من الكلمه)tech like: (GloVe,FastText,Word2Vec)\n",
        "# 4-Auto Correction (تصحيح المدخلات إذا كان فيه خطا ,التحدى هو معرفة هل الكلمة صحيحه ام خطأ اذا قابلت كلمة لا اعرفها ,و متوقف على نسبة الاخطاء فى الكلمه)\n",
        "# 5-Text Similarity (تحديد قرب المعنى و قرب الحروف من مجموعة معينه من الكلمات)\n",
        "# 6-Text Generation(عمل كتابة من طريق الصفر)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3-0WS3Qn6jQf",
      "metadata": {
        "id": "3-0WS3Qn6jQf"
      },
      "outputs": [],
      "source": [
        "from deep_translator import GoogleTranslator\n",
        "from warnings import filterwarnings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "3d7ada29-a5d4-42a9-a6e4-c17b8f16365c",
      "metadata": {
        "id": "3d7ada29-a5d4-42a9-a6e4-c17b8f16365c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "498dc08f-c95c-4314-dec9-67bf7441aa25"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.41.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.23.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.25.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.3)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.7.4)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "96573ccc-57a9-4853-99f9-e769be0a9dce",
      "metadata": {
        "id": "96573ccc-57a9-4853-99f9-e769be0a9dce"
      },
      "outputs": [],
      "source": [
        "# import the librarys"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "_KIZ38CR7vwt",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KIZ38CR7vwt",
        "outputId": "03121f77-35b6-4e10-ae68-984bc3ced99a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.6/8.6 MB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q streamlit"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "C__tac3Y6jPD",
      "metadata": {
        "id": "C__tac3Y6jPD"
      },
      "outputs": [],
      "source": [
        "!pip install -U deep_translator"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "wKFyY3W26jN4",
      "metadata": {
        "id": "wKFyY3W26jN4"
      },
      "outputs": [],
      "source": [
        "import transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "F1fjio3W8Caz",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F1fjio3W8Caz",
        "outputId": "3eaeac55-d8d3-4e09-ff51-7da6f5c9cdea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting app.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile app.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "4VsvI11_8LNj",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VsvI11_8LNj",
        "outputId": "9d3c14b7-5f29-4633-dd39-a1607215fc5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "35.202.216.229\n"
          ]
        }
      ],
      "source": [
        "!wget -q -O- ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "DAlI2Qn4_YY5",
      "metadata": {
        "id": "DAlI2Qn4_YY5"
      },
      "outputs": [],
      "source": [
        "!streamlit run app.py &>/content/logs.txt &"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "UfR8b8nY-xDA",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "UfR8b8nY-xDA",
        "outputId": "dc79ae88-ed4a-4dd0-a68f-487a855d417e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25hnpx: installed 22 in 14.403s\n",
            "your url is: https://neat-cobras-peel.loca.lt\n"
          ]
        }
      ],
      "source": [
        "!npx localtunnel --port 8000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "x3N4D52_BPev",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3N4D52_BPev",
        "outputId": "97786059-eb12-46db-c70d-c89e29c07d24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pyngrok\n",
            "  Downloading pyngrok-7.1.6-py3-none-any.whl (22 kB)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.1)\n",
            "Installing collected packages: pyngrok\n",
            "Successfully installed pyngrok-7.1.6\n"
          ]
        }
      ],
      "source": [
        "!pip install pyngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ukx0nN57BPhN",
      "metadata": {
        "id": "ukx0nN57BPhN"
      },
      "outputs": [],
      "source": [
        "from pyngrok import ngrok"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "01ulqVUqBPj2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "01ulqVUqBPj2",
        "outputId": "808edee4-c97c-425a-c4bc-5f3e0ee058b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "ngrok.set_auth_token(\"2j5sVDMLHk5H7LWu2O9nr0K7DeG_5r5yLnFAaauAjVjDfoWmP\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "M74cqGqHBPme",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M74cqGqHBPme",
        "outputId": "a6eb7209-a7e8-4e81-e022-45c2cd162722"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "nohup: appending output to 'nohup.out'\n",
            "https://fd38-34-72-241-162.ngrok-free.app\n"
          ]
        }
      ],
      "source": [
        "!nohup streamlit run app.py --server.port 80 &\n",
        "tunnel = ngrok.connect(80)  # Use ngrok.connect to establish the tunnel\n",
        "url = tunnel.public_url\n",
        "print(url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "N3ZXkJXWBPpG",
      "metadata": {
        "id": "N3ZXkJXWBPpG"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "HOKu7bhmBPr2",
      "metadata": {
        "id": "HOKu7bhmBPr2"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "12T3IqFuBPue",
      "metadata": {
        "id": "12T3IqFuBPue"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "83ea4c5d-4b1e-4f82-b8d2-dafbf86bf785",
      "metadata": {
        "id": "83ea4c5d-4b1e-4f82-b8d2-dafbf86bf785"
      },
      "outputs": [],
      "source": [
        "import nltk\n",
        "from nltk.chat.util import Chat,reflections"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0d89ffd8-b56f-4e3c-bc05-b203634dfb18",
      "metadata": {
        "id": "0d89ffd8-b56f-4e3c-bc05-b203634dfb18",
        "outputId": "f10f53d6-b31e-43d7-a6e6-511de15daa99"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Here we go the conversation is start duddy.\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "you:  hi\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chatbot: Hey\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "you:  hi\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chatbot: Hi there!\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "you:  hi\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chatbot: Hey\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "you:  how are you\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chatbot: i am doing well\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "you:  how are you\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chatbot: i am fine thanks \n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "you:  how are you\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chatbot: i am doing well\n"
          ]
        },
        {
          "name": "stdin",
          "output_type": "stream",
          "text": [
            "you:  exit\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "chatbot say:مع السلامة يا ابن العبيطه\n"
          ]
        }
      ],
      "source": [
        "pairs=[[\"hello|hi|hey\",['Hello','Hi there!','Hey']],\n",
        "['how are you|how is it going',[\"i am fine thanks \",\"i am doing well\"]],\n",
        "['what is your name',[\"I 'm a chatbot\",\" I am just a bot\"]]]\n",
        "chatbot=Chat(pairs=pairs,reflections=reflections)\n",
        "print(\"Here we go the conversation is start duddy.\")\n",
        "while True:\n",
        "    user_input=input(\"you: \")\n",
        "    if user_input.lower()=='exit':\n",
        "        print('chatbot say:مع السلامة يا ابن العبيطه')\n",
        "        break\n",
        "    response=chatbot.respond(user_input)\n",
        "    print('chatbot:',response)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "2228d405-427e-4b7e-9f47-862a60865ca1",
      "metadata": {
        "id": "2228d405-427e-4b7e-9f47-862a60865ca1"
      },
      "source": [
        "# ----------second exp more intelligence------------"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "zYcDfNT9jp4I",
      "metadata": {
        "id": "zYcDfNT9jp4I"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "GmrvqRM-jull",
      "metadata": {
        "id": "GmrvqRM-jull"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "Jla33Z3b6jS9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jla33Z3b6jS9",
        "outputId": "6cd254bc-a7b5-4bf1-c221-3f4d6c9da2ee"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1712: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoTokenizer,AutoModelWithLMHead,AutoModelForCausalLM\n",
        "tokenizer=AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-medium\")\n",
        "model=AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-medium\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ehRCqBhPaoqS",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehRCqBhPaoqS",
        "outputId": "c664d2a4-cc96-44a9-c750-18e9bfa5107b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "user : اهلا\n",
            "bot:  مرحبًا!!!\n",
            "user : كيف حالك\n",
            "bot:  انا جيد، كيف حالك؟\n",
            "user : q\n"
          ]
        }
      ],
      "source": [
        "def chat(text): #arabic\n",
        "    text=GoogleTranslator(source='ar',target='en').translate(text)\n",
        "    start=True\n",
        "    new_user_input_ids=tokenizer.encode(text+tokenizer.eos_token,return_tensors='pt')\n",
        "    bot_input_ids=torch.cat([chat_history_ids,new_user_input_ids],dim=-1) if not start else new_user_input_ids\n",
        "    start=False\n",
        "    chat_history_ids=model.generate(bot_input_ids,\n",
        "                    max_length=1000,pad_token_id=tokenizer.eos_token_id,\n",
        "                                   no_repeat_ngram_size=3,\n",
        "                                   do_sample=True,\n",
        "                                   top_k=100,\n",
        "                                   top_p=.7,\n",
        "                                   temperature=.8)\n",
        "    reply=tokenizer.decode(chat_history_ids[:,bot_input_ids.shape[-1]:][0],skip_special_tokens=True)\n",
        "    text=GoogleTranslator(source='en',target='ar').translate(reply)\n",
        "    return text\n",
        "while True:\n",
        "    t=input('user : ')\n",
        "    if t=='q':\n",
        "        break\n",
        "    print('bot: ',chat(t))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9hGf3DjmSu4q",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9hGf3DjmSu4q",
        "outputId": "f6986884-193c-443d-8dbe-d6488ac0233e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-07-11 10:47:45.536 \n",
            "  \u001b[33m\u001b[1mWarning:\u001b[0m to view this Streamlit app on a browser, run it with the following\n",
            "  command:\n",
            "\n",
            "    streamlit run /usr/local/lib/python3.10/dist-packages/colab_kernel_launcher.py [ARGUMENTS]\n",
            "2024-07-11 10:47:45.541 Session state does not function when running a script without `streamlit run`\n"
          ]
        }
      ],
      "source": [
        "#!pip install transformers\n",
        "#!pip install -U deep_translator\n",
        "\n",
        "import streamlit as st\n",
        "import nltk\n",
        "from nltk.chat.util import Chat, reflections\n",
        "\n",
        "# nltk.download('popular') # Uncomment if you need to download nltk data\n",
        "\n",
        "st.title(\"Testing some Chatbots\")\n",
        "st.subheader('Choose the model:')\n",
        "model = st.selectbox(\"Select\", ['1-microsoft', '2-reverse'], key='pk1')\n",
        "btn = st.button(\"Submit\", key='pk2')\n",
        "\n",
        "if btn:\n",
        "    st.write(\"Here we go, the conversation is starting, buddy.\")\n",
        "\n",
        "    if model == \"1-microsoft\":\n",
        "        pairs = [\n",
        "            [\"hello|hi|hey\", ['Hello', 'Hi there!', 'Hey']],\n",
        "            ['how are you|how is it going', [\"I am fine, thanks\", \"I am doing well\"]],\n",
        "            ['what is your name', [\"I'm a chatbot\", \"I am just a bot\"]]\n",
        "        ]\n",
        "        chatbot = Chat(pairs=pairs, reflections=reflections)\n",
        "        prompt = st.chat_input(\"You:\", key=\"user_input\")\n",
        "        while prompt:\n",
        "                st.write(f\"user:{prompt}\")\n",
        "                response = chatbot.respond(prompt.lower())\n",
        "                st.chat_message('Chatbot:', response)\n",
        "                prompt = st.chat_input(\"You:\", key=\"user_input\")\n",
        "                if prompt=='exit':\n",
        "                  break\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "D5rJShGM6jVd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "D5rJShGM6jVd",
        "outputId": "9e4459b1-4bc3-4dce-cb53-98d049abaecd"
      },
      "outputs": [
        {
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-47-c3ee68e32b48>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mt\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user : '\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m    849\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             )\n\u001b[0;32m--> 851\u001b[0;31m         return self._input_request(str(prompt),\n\u001b[0m\u001b[1;32m    852\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    853\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_header\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ],
      "source": [
        "def chat(text): #arabic\n",
        "    text=GoogleTranslator(source='ar',target='en').translate(text)\n",
        "    start=True\n",
        "    new_user_input_ids=tokenizer.encode(text+tokenizer.eos_token,return_tensors='pt')\n",
        "    bot_input_ids=torch.cat([chat_history_ids,new_user_input_ids],dim=-1) if not start else new_user_input_ids\n",
        "    start=False\n",
        "    chat_history_ids=model.generate(bot_input_ids,\n",
        "                    max_length=1000,pad_token_id=tokenizer.eos_token_id,\n",
        "                                   no_repeat_ngram_size=3,\n",
        "                                   do_sample=True,\n",
        "                                   top_k=100,\n",
        "                                   top_p=.7,\n",
        "                                   temperature=.8)\n",
        "    reply=tokenizer.decode(chat_history_ids[:,bot_input_ids.shape[-1]:][0],skip_special_tokens=True)\n",
        "    text=GoogleTranslator(source='en',target='ar').translate(reply)\n",
        "    return text\n",
        "while True:\n",
        "    t=input('user : ')\n",
        "    if t=='q':\n",
        "        break\n",
        "    print('bot: ',chat(t))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "VfrGAQYvYBIv",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "VfrGAQYvYBIv",
        "outputId": "4338a0e4-995d-4959-d6eb-46f70bf46948"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pytorch-lightning\n",
            "  Downloading pytorch_lightning-2.3.3-py3-none-any.whl (812 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.3/812.3 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (1.25.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2.3.0+cu121)\n",
            "Requirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.66.4)\n",
            "Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (6.0.1)\n",
            "Requirement already satisfied: fsspec[http]>=2022.5.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (2023.6.0)\n",
            "Collecting torchmetrics>=0.7.0 (from pytorch-lightning)\n",
            "  Downloading torchmetrics-1.4.0.post0-py3-none-any.whl (868 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m868.8/868.8 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (24.1)\n",
            "Requirement already satisfied: typing-extensions>=4.4.0 in /usr/local/lib/python3.10/dist-packages (from pytorch-lightning) (4.12.2)\n",
            "Collecting lightning-utilities>=0.10.0 (from pytorch-lightning)\n",
            "  Downloading lightning_utilities-0.11.3.post0-py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (2.31.0)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning) (3.9.5)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning) (67.7.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (3.15.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (3.1.4)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=2.0.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=2.0.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=2.0.0->pytorch-lightning)\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=2.0.0->pytorch-lightning)\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=2.0.0->pytorch-lightning)\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=2.0.0->pytorch-lightning)\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=2.0.0->pytorch-lightning)\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=2.0.0->pytorch-lightning)\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=2.0.0->pytorch-lightning)\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=2.0.0->pytorch-lightning)\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=2.0.0->pytorch-lightning)\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.0.0->pytorch-lightning) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=2.0.0->pytorch-lightning)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.82-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m16.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning) (4.0.3)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.0.0->pytorch-lightning) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>=2022.5.0->pytorch-lightning) (2024.6.2)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.0.0->pytorch-lightning) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, lightning-utilities, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, torchmetrics, pytorch-lightning\n",
            "Successfully installed lightning-utilities-0.11.3.post0 nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.82 nvidia-nvtx-cu12-12.1.105 pytorch-lightning-2.3.3 torchmetrics-1.4.0.post0\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-lightning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "aMf6UNEoY_xU",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aMf6UNEoY_xU",
        "outputId": "0db0f498-7d04-4ea4-c045-5aae9fa29b4d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.3.0+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.20.5 in /usr/local/lib/python3.10/dist-packages (from torch) (2.20.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch) (12.1.105)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.3.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch) (12.5.82)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4.0,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "CanCmZdJZIbC",
      "metadata": {
        "id": "CanCmZdJZIbC"
      },
      "outputs": [],
      "source": [
        "import torch"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}